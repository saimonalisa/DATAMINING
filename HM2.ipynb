{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e44f0b",
   "metadata": {},
   "source": [
    "Importing pandas and ydata_profiling libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb6ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e343cd33",
   "metadata": {},
   "source": [
    "Reading the csv file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2fed9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"red_wine.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d505c",
   "metadata": {},
   "source": [
    "Pandas profiling for the red_Wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c7145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2546c0c",
   "metadata": {},
   "source": [
    "Saving the report as html file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe4635c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56f171855ba49b7b87340a6d5ef8575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2654a53db3b34c608f69ce8da905aee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a5b7d22ff241179ea89a8c76d8937f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f37f9df0c84edb88d37cf5e328506e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile.to_file(\"red_wine_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de41f9",
   "metadata": {},
   "source": [
    "Splitting the dataset into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb02302",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_frame.drop('type', axis=1)\n",
    "Y = data_frame['type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79472752",
   "metadata": {},
   "source": [
    "DEFINING THE MODELS TO FIT THE DATA AND ANALYZE THE METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0acb16d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classification_models = {\n",
    "    'ZeroR': DummyClassifier(strategy='most_frequent'),\n",
    "    'OneR': DecisionTreeClassifier(max_depth=1),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2344bb58",
   "metadata": {},
   "source": [
    "Analyzing the performance metrics of 10-fold cross-validation for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef8f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "metrics = []\n",
    "for name, model in classification_models.items():\n",
    "    scores = cross_val_score(model, X, Y, cv=10, scoring='accuracy')\n",
    "    auc_scores = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\n",
    "    mean_score = scores.mean()\n",
    "    mean_auc = auc_scores.mean()\n",
    "    metrics.append((name, mean_score, mean_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3121240c",
   "metadata": {},
   "source": [
    "Convert the results to a Pandas DataFrame and print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4899f0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model  Accuracy (mean)  AUC (mean)\n",
      "0                   ZeroR         0.528887    0.500000\n",
      "1                    OneR         0.798790    0.802581\n",
      "2     Logistic Regression         0.784785    0.879902\n",
      "3             Naive Bayes         0.821627    0.895408\n",
      "4           Decision Tree         0.742710    0.751491\n",
      "5  Support Vector Machine         0.535844    0.868920\n",
      "6           Random Forest         0.800575    0.888833\n"
     ]
    }
   ],
   "source": [
    "final_metrics = pd.DataFrame(metrics, columns=['Model', 'Accuracy (mean)', 'AUC (mean)'])\n",
    "print(final_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a889f",
   "metadata": {},
   "source": [
    "Encoding the target variable type 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93f95729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "l = LabelEncoder()\n",
    "data_frame['type'] = l.fit_transform(data_frame['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408fdb16",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "792e270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, x_test, Y_train, y_test = train_test_split(data_frame.drop('type', axis=1), data_frame['type'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7adb73",
   "metadata": {},
   "source": [
    "Fit the model to the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5c91069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df3e707",
   "metadata": {},
   "source": [
    "Predicting the probabilities for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4578374",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_forest.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f9f63",
   "metadata": {},
   "source": [
    "Computing false positive rate, true positive rate, threshold values and AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3cf3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred[:,1])\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb27365e",
   "metadata": {},
   "source": [
    "Plotting the ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5a5a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import get_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b76e6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='grey', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Reciever Charactersticks')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f028b7",
   "metadata": {},
   "source": [
    "Loading white_wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad00caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame2 = pd.read_csv(\"white_wine.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb0f216",
   "metadata": {},
   "source": [
    "Split the dataset into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3668d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = data_frame2.drop('type', axis=1)\n",
    "Q = data_frame2['type']\n",
    "\n",
    "\n",
    "classification_models = {\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "\n",
    "results2 = []\n",
    "for name, model in classification_models.items():\n",
    "    scores = cross_val_score(model, P, Q, cv=10, scoring='accuracy')\n",
    "    auc_scores = cross_val_score(model, P, Q, cv=10, scoring='roc_auc')\n",
    "    mean_score_end = scores.mean()\n",
    "    mean_auc_end = auc_scores.mean()\n",
    "    results2.append((name, mean_score_end, mean_auc_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d993aa8",
   "metadata": {},
   "source": [
    "Converting the results to a Pandas DataFrame and printing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04b29eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Accuracy (mean)  AUC(mean)\n",
      "0  Naive Bayes         0.932143       0.95\n"
     ]
    }
   ],
   "source": [
    "results_dataframe = pd.DataFrame(results2, columns=['Model', 'Accuracy (mean)', 'AUC(mean)'])\n",
    "print(results_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
